# Default configuration for Black-Scholes Inverse Problem Project
# Configuration for implied volatility surface calibration using regularization and PINN

# Black-Scholes model parameters
bs:
  # Default risk-free rate (annualized)
  r: 0.05
  
  # Default dividend yield (annualized, continuous)
  q: 0.02
  
  # Default spot price (will be overridden by market data)
  S0: 100.0
  
  # Greeks calculation settings
  greeks:
    epsilon: 1.0e-6  # Numerical differentiation step size
    
# Data acquisition settings
data:
  # Ticker symbol for SPY or other underlying
  ticker: "SPY"
  
  # Date for option chain (YYYY-MM-DD format, or "latest" for most recent)
  date: "latest"
  
  # Data source: "yahoo" or "optionmetrics"
  source: "yahoo"
  
  # Filtering criteria
  filter:
    min_time_to_maturity: 0.02  # Minimum T in years (~7 days)
    max_time_to_maturity: 2.0   # Maximum T in years
    min_moneyness: 0.8          # K/S minimum ratio
    max_moneyness: 1.2          # K/S maximum ratio
    min_volume: 10              # Minimum trading volume
    min_open_interest: 50       # Minimum open interest
  
  # Output paths
  output_dir: "data/processed"
  raw_data_dir: "data/raw"

# Implied volatility surface parameterization
sigma_model:
  # Model type: "bilinear", "spline", "neural_network"
  type: "bilinear"
  
  # For bilinear interpolation
  bilinear:
    n_strike_nodes: 10   # Number of strike grid points
    n_time_nodes: 5      # Number of time grid points
    
  # For spline interpolation  
  spline:
    strike_order: 3      # B-spline order for strike dimension
    time_order: 3        # B-spline order for time dimension
    n_strike_knots: 15   # Number of knots for strike
    n_time_knots: 8      # Number of knots for time
    
  # For neural network
  neural_network:
    hidden_layers: [32, 32]  # Hidden layer sizes
    activation: "tanh"       # Activation function: "relu", "tanh", "sigmoid"
    dropout: 0.0             # Dropout rate
    batch_norm: false        # Use batch normalization
    input_transform: "log_moneyness"  # "raw", "log_moneyness", "normalized"

# Loss function and regularization
loss:
  # Data fitting loss weight
  data_weight: 1.0
  
  # Regularization weights
  regularization:
    # Smoothness regularization (Tikhonov)
    smoothness_weight: 0.01
    smoothness_order: 2  # Order of derivative (1 or 2)
    
    # No-arbitrage constraints (soft constraints)
    no_arbitrage:
      enabled: true
      butterfly_weight: 0.1      # Convexity constraint weight
      calendar_spread_weight: 0.05  # Time monotonicity weight
      
    # Prior shape constraint (optional)
    prior_weight: 0.0
    prior_volatility: 0.2  # Center volatility for prior
    
  # PINN physics-informed regularization
  pinn:
    enabled: false  # Enable PINN regularization
    pde_weight: 0.05  # Weight for PDE residual
    n_collocation_points: 100  # Number of collocation points for PDE
    boundary_weight: 0.01  # Weight for boundary conditions

# Optimization settings
optimization:
  # Optimizer type: "adam", "lbfgs", "sgd", "hybrid"
  optimizer: "hybrid"
  
  # Adam optimizer settings
  adam:
    learning_rate: 0.01
    betas: [0.9, 0.999]
    weight_decay: 0.0
    max_iterations: 1000
    
  # L-BFGS optimizer settings
  lbfgs:
    max_iterations: 100
    line_search_fn: "strong_wolfe"
    tolerance_grad: 1.0e-7
    tolerance_change: 1.0e-9
    history_size: 100
    
  # Hybrid approach (Adam then L-BFGS)
  hybrid:
    adam_iterations: 500
    lbfgs_iterations: 100
    
  # Convergence criteria
  convergence:
    loss_tolerance: 1.0e-6
    gradient_tolerance: 1.0e-7
    patience: 50  # Early stopping patience
    
  # Learning rate scheduler
  scheduler:
    enabled: true
    type: "reduce_on_plateau"  # "step", "exponential", "reduce_on_plateau"
    patience: 20
    factor: 0.5
    min_lr: 1.0e-6

# Training and evaluation
training:
  # Random seed for reproducibility
  seed: 42
  
  # Validation split (if using held-out data)
  validation_split: 0.1
  
  # Logging
  log_interval: 10  # Log every N iterations
  checkpoint_interval: 100  # Save checkpoint every N iterations
  
  # Device: "cpu", "cuda", "mps" (for Apple Silicon)
  device: "cpu"
  
  # Numerical precision
  dtype: "float32"  # "float32" or "float64"

# Visualization settings
visualization:
  # Output directory for plots
  output_dir: "results/plots"
  
  # Figure settings
  figure:
    dpi: 150
    format: "png"  # "png", "pdf", "svg"
    style: "seaborn-v0_8-darkgrid"
    
  # 3D surface plot settings
  surface_plot:
    elevation: 30
    azimuth: 45
    colormap: "viridis"
    
  # Convergence plot settings
  convergence_plot:
    show_components: true  # Show individual loss components
    log_scale: true
    
  # Residual plot settings
  residual_plot:
    bins: 50
    show_histogram: true

# Experiment tracking
experiment:
  # Experiment name (auto-generated if not specified)
  name: null
  
  # Output directory for results
  output_dir: "results"
  
  # Save checkpoints
  save_checkpoints: true
  checkpoint_dir: "checkpoints"
  
  # Metrics to track
  metrics:
    - "loss"
    - "data_loss"
    - "regularization_loss"
    - "rmse"
    - "max_abs_error"
    - "arbitrage_violations"

# Paths
paths:
  project_root: "."
  data_dir: "data"
  models_dir: "models"
  results_dir: "results"
  logs_dir: "logs"