{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d9160e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "## SPY Options Data from WRDS OptionMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde238fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "repo_path = os.getenv(\"REPO_PATH\") or os.path.abspath(\"..\")\n",
    "sys.path.append(os.path.join(repo_path, \"src\"))\n",
    "\n",
    "from data_loader import (\n",
    "    load_raw_data,\n",
    "    get_spot_price,\n",
    "    prepare_option_data,\n",
    "    split_data\n",
    ")\n",
    "from preprocessing import (\n",
    "    clean_data,\n",
    "    compute_implied_volatilities,\n",
    "    normalize_features,\n",
    "    create_model_dataset,\n",
    "    add_additional_features\n",
    ")\n",
    "from visualize import (\n",
    "    plot_volatility_smile,\n",
    "    plot_volatility_surface_3d,\n",
    "    plot_volatility_heatmap,\n",
    "    plot_term_structure,\n",
    "    check_calendar_arbitrage,\n",
    "    check_butterfly_arbitrage,\n",
    "    plot_arbitrage_analysis,\n",
    "    plot_bid_ask_spread_analysis,\n",
    "    summarize_data_characteristics\n",
    ")\n",
    "from utils import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_context(\"talk\", font_scale=0.9)\n",
    "pd.set_option(\"display.max_columns\", 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910192db",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcbff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = os.getenv(\"RAW_DATA_PATH\") or os.path.join(repo_path, \"data\", \"raw\")\n",
    "ticker_name = os.getenv(\"TICKER_NAME\", \"SPY\")\n",
    "date = os.getenv(\"TRADE_DATE\", \"2023-01-03\")\n",
    "\n",
    "if not os.path.isdir(raw_data_path):\n",
    "    raise FileNotFoundError(f\"Raw data path not found: {raw_data_path}\")\n",
    "\n",
    "print(\"Loading raw data...\")\n",
    "data = load_raw_data(raw_data_path, ticker_name, date)\n",
    "\n",
    "if len(data) == 0:\n",
    "    raise ValueError(\"No parquet files were loaded; check RAW_DATA_PATH and filename patterns.\")\n",
    "\n",
    "print(\"\n",
    "Loaded datasets:\")\n",
    "for key, df in data.items():\n",
    "    print(f\"  {key}: {len(df)} rows, {len(df.columns)} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e103280",
   "metadata": {},
   "source": [
    "## 2. Examine Option Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_df = data.get('option_price')\n",
    "if op_df is None:\n",
    "    raise KeyError(\"option_price parquet missing; expected load_raw_data to find *_option_price.parquet\")\n",
    "\n",
    "print(f\"Option Price Data Shape: {op_df.shape}\")\n",
    "print(f\"\n",
    "Columns: {list(op_df.columns)}\")\n",
    "print(\"\n",
    "First few rows:\")\n",
    "op_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209945d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary Statistics:\")\n",
    "op_df[['strike_price', 'best_bid', 'best_offer', 'volume', 'open_interest', 'impl_volatility']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c10628",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\n",
    "Option Type Distribution:\")\n",
    "print(op_df['cp_flag'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e430e8",
   "metadata": {},
   "source": [
    "## 3. Market Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "security_df = data.get('security_price')\n",
    "zero_curve_df = data.get('zero_curve')\n",
    "if security_df is None or zero_curve_df is None:\n",
    "    raise KeyError(\"security_price and zero_curve parquet files are required for downstream processing\")\n",
    "\n",
    "spot_price = get_spot_price(security_df)\n",
    "print(f\"SPY Spot Price: ${spot_price:.2f}\")\n",
    "\n",
    "print(\"\n",
    "Zero Curve:\")\n",
    "zero_curve_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e1056",
   "metadata": {},
   "source": [
    "## 4. Prepare Option Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing option data...\")\n",
    "prepared_df = prepare_option_data(\n",
    "    op_df,\n",
    "    spot_price,\n",
    "    date,\n",
    "    zero_curve_df,\n",
    "    data.get('distr_proj', None)\n",
    ")\n",
    "\n",
    "print(f\"Prepared data shape: {prepared_df.shape}\")\n",
    "print(\"\n",
    "New columns added:\", [col for col in prepared_df.columns if col not in op_df.columns])\n",
    "prepared_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdb697",
   "metadata": {},
   "source": [
    "## 5. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before cleaning: {len(prepared_df)} options\")\n",
    "cleaned_df = clean_data(prepared_df)\n",
    "print(f\"After cleaning: {len(cleaned_df)} options\")\n",
    "print(f\"Removed: {len(prepared_df) - len(cleaned_df)} options ({100*(len(prepared_df) - len(cleaned_df))/len(prepared_df):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282362cc",
   "metadata": {},
   "source": [
    "## 6. Compute Implied Volatilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing implied volatilities...\")\n",
    "iv_df = compute_implied_volatilities(cleaned_df)\n",
    "print(f\"Successfully computed IV for {len(iv_df)} options\")\n",
    "\n",
    "if 'impl_volatility' in iv_df.columns:\n",
    "    valid_market_iv = iv_df[iv_df['impl_volatility'].notna()]\n",
    "    if len(valid_market_iv) > 0:\n",
    "        print(\"\n",
    "IV Comparison (computed vs market):\")\n",
    "        print(f\"  Mean difference: {(valid_market_iv['computed_iv'] - valid_market_iv['impl_volatility']).mean():.4f}\")\n",
    "        print(f\"  Median difference: {(valid_market_iv['computed_iv'] - valid_market_iv['impl_volatility']).median():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b620c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df = add_additional_features(iv_df)\n",
    "print(f\"Final dataset shape: {iv_df.shape}\")\n",
    "print(\"\n",
    "Summary statistics for computed IV:\")\n",
    "iv_df['computed_iv'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912738cf",
   "metadata": {},
   "source": [
    "### 6a. Dataset Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize_data_characteristics(iv_df)\n",
    "print(\"Key ranges and counts:\")\n",
    "summary_df = pd.Series(summary, name=\"value\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94137eaf",
   "metadata": {},
   "source": [
    "## 7. Visualize Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549770a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(iv_df['moneyness'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(1.0, color='red', linestyle='--', label='ATM')\n",
    "axes[0].set_xlabel('Moneyness (K/S)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Moneyness')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(iv_df['T'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Time to Maturity (years)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Time to Maturity')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732f951",
   "metadata": {},
   "source": [
    "## 8. Smiles and Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maturity_buckets = [30, 60, 90, 180]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "plot_volatility_smile(iv_df, maturity_buckets, option_type='C', ax=axes[0])\n",
    "plot_volatility_smile(iv_df, maturity_buckets, option_type='P', ax=axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plot_term_structure(iv_df, moneyness_levels=[0.9, 1.0, 1.1], ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_volatility_surface_3d(iv_df, iv_col='computed_iv', interpolate=True, grid_size=50)\n",
    "plt.show()\n",
    "\n",
    "fig = plot_volatility_heatmap(iv_df, iv_col='computed_iv', grid_size=(40, 40))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8dea0",
   "metadata": {},
   "source": [
    "## 9. Arbitrage and Market Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc20ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_violations = check_calendar_arbitrage(iv_df, iv_col='computed_iv', moneyness_tolerance=0.02)\n",
    "butterfly_violations = check_butterfly_arbitrage(iv_df, price_col='mid_price', maturity_tolerance=2)\n",
    "\n",
    "print(f\"Calendar arbitrage violations: {len(calendar_violations)}\")\n",
    "print(f\"Butterfly arbitrage violations: {len(butterfly_violations)}\")\n",
    "\n",
    "if len(calendar_violations) > 0:\n",
    "    display(calendar_violations.head())\n",
    "if len(butterfly_violations) > 0:\n",
    "    display(butterfly_violations.head())\n",
    "\n",
    "fig = plot_arbitrage_analysis(calendar_violations, butterfly_violations)\n",
    "plt.show()\n",
    "\n",
    "fig = plot_bid_ask_spread_analysis(iv_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd84deb",
   "metadata": {},
   "source": [
    "## 10. Split and Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_data(iv_df, train_ratio=0.8, random_state=42)\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = ['log_moneyness', 'T']\n",
    "target = 'computed_iv'\n",
    "\n",
    "X_train, y_train, norm_params = create_model_dataset(\n",
    "    train_df,\n",
    "    input_features=input_features,\n",
    "    target=target,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "X_test, y_test, _ = create_model_dataset(\n",
    "    test_df,\n",
    "    input_features=input_features,\n",
    "    target=target,\n",
    "    normalize=False\n",
    ")\n",
    "\n",
    "test_df_normalized = test_df.copy()\n",
    "for feature in input_features:\n",
    "    mean = norm_params[feature]['mean']\n",
    "    std = norm_params[feature]['std'] + 1e-8\n",
    "    test_df_normalized[feature] = (test_df[feature] - mean) / std\n",
    "X_test = test_df_normalized[input_features].values\n",
    "\n",
    "print(f\"\n",
    "Training set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test set shape: X={X_test.shape}, y={y_test.shape}\")\n",
    "print(\"\n",
    "Normalization parameters:\")\n",
    "norm_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97c0ed",
   "metadata": {},
   "source": [
    "## 11. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = os.path.join(repo_path, \"data\", \"processed\")\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "train_df.to_parquet(os.path.join(processed_path, f\"{ticker_name}_{date.replace('-', '')}_train.parquet\"))\n",
    "test_df.to_parquet(os.path.join(processed_path, f\"{ticker_name}_{date.replace('-', '')}_test.parquet\"))\n",
    "\n",
    "np.save(os.path.join(processed_path, f\"{ticker_name}_{date.replace('-', '')}_X_train.npy\"), X_train)\n",
    "np.save(os.path.join(processed_path, f\"{ticker_name}_{date.replace('-', '')}_y_train.npy\"), y_train)\n",
    "np.save(os.path.join(processed_path, f\"{ticker_name}_{date.replace('-', '')}_X_test.npy\"), X_test)\n",
    "np.save(os.path.join(processed_path, f\"{ticker_name}_{date.replace('-', '')}_y_test.npy\"), y_test)\n",
    "\n",
    "import json\n",
    "with open(os.path.join(processed_path, f\"{ticker_name}_{date.replace('-', '')}_norm_params.json\"), 'w') as f:\n",
    "    json.dump(norm_params, f, indent=4)\n",
    "\n",
    "print(f\"Processed data saved to: {processed_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055a284",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Loaded WRDS OptionMetrics raw parquet files and extracted spot/zero-curve context\n",
    "- Cleaned invalid quotes and computed implied vols using Blackâ€“Scholes\n",
    "- Profiled ranges (moneyness, maturities) and visualized smiles, surfaces, and term structures\n",
    "- Checked calendar/butterfly arbitrage and bid-ask quality for anomalies\n",
    "- Normalized features, split train/test, and saved processed artifacts for downstream modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivpinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
